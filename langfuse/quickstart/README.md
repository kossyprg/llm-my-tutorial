## Langfuse ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

Langfuse ã«é–¢ã™ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã§ã™ã€‚

å‚è€ƒï¼š[Langfuse Docs](https://langfuse.com/docs)

## å®Ÿè¡Œæ–¹æ³•

1. `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ç’°å¢ƒå¤‰æ•°ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

```
OPENAI_API_KEY="<your-openai-api-key>"

# ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ä»¥ä¸‹ãŒå¿…é ˆ
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_PUBLIC_KEY="pk-lf-..."
LANGFUSE_HOST="https://cloud.langfuse.com" # ğŸ‡ªğŸ‡º EU region
# LANGFUSE_HOST="https://us.cloud.langfuse.com" # ğŸ‡ºğŸ‡¸ US region
```

2. `Dockerfile` ã‚’ä½¿ç”¨ã—ã¦ãƒ“ãƒ«ãƒ‰ã—ã¾ã™ã€‚

```bash
docker build -t langfuse-quickstart .
```

3. ãƒ“ãƒ«ãƒ‰ã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚`-v`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’ãƒã‚¦ãƒ³ãƒˆã™ã‚‹ã¨ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ä¿®æ­£ãŒã‚³ãƒ³ãƒ†ãƒŠç’°å¢ƒã«ã‚‚åæ˜ ã•ã‚Œã¾ã™ã€‚

Windows(cmd)ã®å ´åˆ
```cmd
REM For Windows(cmd)
docker run -it --rm -v "%cd%":/home/user/app langfuse-quickstart /bin/bash
```

4. æ‰€æœ›ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```bash
python main_decorator.py
```

5. çµ‚äº†ã™ã‚‹éš›ã¯`exit`ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„

```bash
exit
```

## ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰

### ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ã†æ–¹æ³•
[main_decorator.py](main_decorator.py)

å‚è€ƒï¼š[Get Started with Langfuse Tracing](https://langfuse.com/docs/get-started#log-your-first-llm-call-to-langfuse)

`@decorator()` ã‚’ä½¿ã†ã¨ç°¡å˜ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã§ãã¾ã™ã€‚

```python
from langfuse.decorators import observe
from langfuse.openai import openai # OpenAI integration

@observe()
def story():
    return openai.chat.completions.create(
        model="gpt-4o",
        max_tokens=150,
        temperature=0.8,
        messages=[
          {"role": "system", "content": "ã‚ãªãŸã¯ãƒ¦ãƒ¼ãƒ¢ã‚¢ã®ã‚»ãƒ³ã‚¹ã®ã‚ã‚‹èŠ¸äººã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ã®å‡ºã™ãŠé¡Œã«å¯¾ã—ã¦æ´’è½ã®åˆ©ã„ãŸé¢ç™½ã„å›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"},
          {"role": "user", "content": "ã“ã‚“ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(Large Language Model: LLM)ã¯å«Œã ã€‚ã©ã‚“ãªLLM?"},
          # (omitted)
        ],
    ).choices[0].message.content
 
@observe()
def decorator_example():
    return story()
```

**ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ­ã‚°ã®ä¾‹**

`Trace` ã‚„ `Span` ã®åå‰ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é–¢æ•°åã«ãªã‚Šã¾ã™ã€‚

![ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸå ´åˆã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ­ã‚°ã®ä¾‹](img/langfuse_quickstart_decorator_trace_log_example.png)

`@decorator(name="...")` ã®ã‚ˆã†ã« `name` ã‚’ä¸ãˆã‚‹ã¨ã€Langfuse ã«è¡¨ç¤ºã•ã‚Œã‚‹ `Trace` ã‚„ `Span` ã®åå‰ã‚’å¤‰ãˆã‚‰ã‚Œã¾ã™ã€‚

![ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã®nameå±æ€§ã‚’æŒ‡å®šã—ãŸå ´åˆã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ­ã‚°ã®ä¾‹](img/langfuse_quickstart_decorator_trace_log_example_2.png)


### ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’ä½¿ã†æ–¹æ³•
[main_callback.py](main_callback.py)

å‚è€ƒï¼š[Get Started with Langfuse Tracing](https://langfuse.com/docs/get-started#log-your-first-llm-call-to-langfuse)

`langfuse` ã® `CallbackHandler` ã‚’æ¸¡ã™ã“ã¨ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã§ãã¾ã™ã€‚

```python
from langfuse.callback import CallbackHandler

def callback_example():
    # callback handler ã®è¨­å®š
    langfuse_handler = CallbackHandler(
        secret_key=os.environ['LANGFUSE_SECRET_KEY'],
        public_key=os.environ['LANGFUSE_PUBLIC_KEY'],
        host=os.environ['LANGFUSE_HOST'],
    )

    # (ä¸­ç•¥) 

    # (c) Undertale
    for chunk in runnable.stream(
        input="ã‚±ãƒ„ã‚¤ãŒã¿ãªãã£ãŸã€‚",
        config={"callbacks": [langfuse_handler], "run_name": "ãƒ‹ãƒ³ã‚²ãƒ³"} # callbacks ã«æ¸¡ã™
    ):
        print(chunk, end="", flush=True)
        time.sleep(0.1)
```

**ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ­ã‚°ã®ä¾‹**

![ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’ä½¿ã£ãŸå ´åˆã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ­ã‚°ã®ä¾‹](img/langfuse_quickstart_callback_trace_log_example.png)

**ãŠã¾ã‘** 

`stream()` ã®ä½¿ç”¨ä¾‹

![Determination](img/langfuse_quickstart_callback_stream_example.gif)
